{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bf79c1-f232-4dc1-8d86-4ea8f8fbdb2a",
   "metadata": {},
   "source": [
    "# MOD16 Calibration (via MCMC) Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d360a-a46c-419e-b700-77e3306257d1",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "2. [Before You Get Started](#Before-You-Get-Started)\n",
    "   - [The HDF5 Cal-Val Data](#The-HDF5-Cal-Val-Data)\n",
    "   - [The YAML Configuration File](#The-YAML-Configuration-File)\n",
    "   - [The YAML Priors File](#The-YAML-Priors-File)\n",
    "3. [Running the Calibration](#Running-the-Calibration)\n",
    "   - [Output Files](#Output-Files)\n",
    "   - [Using k-folds Cross Validation](#Using-k-folds-Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c23c5-f860-4d0f-a593-cbfefb665dea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "The MOD16 calibration suite is intended to be used at the command line.\n",
    "\n",
    "So, for starters, let's confirm where we are on our file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaed5c7-2e99-48fa-b7be-895569c2fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ee7d6-2eb0-43fb-ba7f-cc97c4084579",
   "metadata": {},
   "source": [
    "**Note that when we start an example with a `!` character, we're actually sending that command to the command line (the Unix Shell or Windows Power Shell); it's not Python code.**\n",
    "\n",
    "The `notebooks` directory isn't a useful place to start, but we can't change directories inside a Jupyter Notebook. So, for now, note that we will interact with the `calibration.py` script by using a relative path to that file; it is located in the `mod16` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32af69-4a58-4dc9-a561-057ead6d7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ../mod16/calibration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8d541-e89b-4335-a0f1-b9ea17802048",
   "metadata": {},
   "source": [
    "The script is intended to be called like:\n",
    "\n",
    "```sh\n",
    "python calibration.py <command> <options>\n",
    "```\n",
    "\n",
    "If you run the `calibration.py` script without any arguments, you'll see what `COMMANDS` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7003621-4fb0-4c13-84a0-8f46c1813c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3e0d6-15ee-4926-ac3f-e8cb0fdc7f80",
   "metadata": {},
   "source": [
    "And you can get help on individual commands using `--help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f25b91-b652-4ec0-85ee-1a2fb1b8f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py tune --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aba9dd-7d08-4dad-b211-c9a9043c67cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before You Get Started\n",
    "\n",
    "You need three files prepared before you can start calibration:\n",
    "\n",
    "- **HDF5 Cal-Val data file:** This an HDF5 file that contains all the data (inputs and observed fluxes) at the tower sites needed to run the calibration.\n",
    "- **YAML configuration file:** This is a YAML file (`*.yaml`) that specifies all the options and file paths for *your* calibration run.\n",
    "- **YAML priors file:** This is a YAML file that specifies the priors for every parameter in MOD16.\n",
    "\n",
    "### The HDF5 Cal-Val Data\n",
    "\n",
    "The structure of this file is defined in the [module-level docstring of `calibration.py`](https://arthur-e.github.io/MOD16/calibration.html)\n",
    "\n",
    "### The YAML Configuration File\n",
    "\n",
    "Below is a template for the YAML configuration file; you can copy it and modify it to suit your needs.\n",
    "\n",
    "```yaml\n",
    "---\n",
    "BPLUT:\n",
    "  ET: \"/home/user/MOD16_BPLUT_CX.X_05deg_MCD43B_Albedo_MERRA.csv\"\n",
    "data:\n",
    "  file: \"/home/user/VIIRS_MOD16_tower_site_latent_heat_and_drivers_v5.h5\"\n",
    "  class_map: state/PFT # HDF5 field name for PFT map\n",
    "  classes: [1,2,3,4,5,6,7,8,9,10,12] # The unique and valid PFT codes\n",
    "  # If a time-varying PFT map is used, this should be true and the corresponding\n",
    "  #   \"class_map\" array (see above) should be a (T x N) array\n",
    "  classes_are_dynamic: false\n",
    "  target_observable: FLUXNET/latent_heat # HDF5 field name\n",
    "  sites_blacklisted: []\n",
    "  # The name of the HDF5 group that contains surface meteorology data\n",
    "  met_group: MERRA2\n",
    "  # The name of the HDF5 datasets for albedo, fPAR, LAI, etc.\n",
    "  datasets:\n",
    "    albedo: MODIS/MCD43GF_black_sky_sw_albedo\n",
    "    fPAR: MODIS/MOD15A2HGF_fPAR_interp\n",
    "    LAI: MODIS/MOD15A2HGF_LAI_interp\n",
    "optimization:\n",
    "  backend_template: \"/home/user/20231218_MOD16_%s_calibration_PFT%d.nc4\"\n",
    "  prior: \"/home/user/MOD16/mod16/data/MOD16_BPLUT_prior_20231218.yaml\"\n",
    "  chains: 3 # Number of chains to run\n",
    "  draws: 1000 # Number of draws from the posterior distribution\n",
    "  tune: scaling # Which hyperparameter to tune\n",
    "  scaling: 0.001 # Initial scale factor for epsilon\n",
    "  objective: RMSD # Objective function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e4da0-bcf6-456e-9a57-36e7cedba5fd",
   "metadata": {},
   "source": [
    "Some particular configuration options to pay attention to include are as follows.\n",
    "\n",
    "In the `BPLUT` group:\n",
    "\n",
    "- `ET:` This is the path to the existing MOD16 BPLUT, i.e., the old BPLUT. It is used to fill-in any parameters that are not being calibrated.\n",
    "\n",
    "In the `data` group:\n",
    "\n",
    "- `file:` This is the file path to the HDF5 calibration-validation (Cal-Val) File.\n",
    "- `classes:` This is a list of the valid numeric PFT codes. The Calibration API will use this to determine when all PFTs have been calibrated.\n",
    "- `classes_are_dynamic:` The PFT classes can be static (this is set to `false`) or vary in time (`true`); in the latter case, we mean that tower's PFT may change at every time step (potentially). Most likely, tower PFT changes yearly, but if `classes_are_dynamic` is `true`, then the `class_map` should be a (T x N) array where T is the number of (daily) time steps.\n",
    "\n",
    "In the `optimization` group:\n",
    "\n",
    "- `backend_template:` This is the file path to an output file that *will be created* after a successful run. The filename should have two formatting characters, `%s` where the model name (usually `\"ET\"`) should go and `%d` where the numeric PFT code should go. If this file already exists, it will be overwritten!\n",
    "- `prior:` This is the file path to the YAML priors file, **which is described in the next section.**\n",
    "- `draws:` You may want to increase this to increase the number of draws from the posterior distribution. However, starting with a small number of draws, for faster completion, will help you verify everything is working as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf80a04-7d7c-4bab-91fd-c286413c1a4b",
   "metadata": {},
   "source": [
    "### The YAML Priors File\n",
    "\n",
    "The priors file will look different depending on the prior distributions you have settled on for your unique use case. In the current version of MOD16, [these are the free parameters to be calibrated.](https://github.com/arthur-e/MOD16?tab=readme-ov-file#free-parameters) However, the minimum temperature and vapor pressure deficit (VPD) ramp functions are fixed at the same values as MOD17, so these are not calibrated in the current scheme.\n",
    "\n",
    "In the current scheme of our calibration software, we use the following functional forms for each prior:\n",
    "\n",
    "- `gl_sh`, or $g_{SH}$, uses a LogNormal prior\n",
    "- `gl_wv`, or $g_{WV}$, uses a LogNormal prior\n",
    "- `g_cuticular`, or $g_{cuticular}$, uses a LogNormal prior\n",
    "- `csl`, or $C_L$, uses a LogNoraml prior\n",
    "- `rbl_min`, or $r_{\\text{BL,min}}$, uses a Uniform prior\n",
    "- `rbl_max`, or $r_{\\text{BL,max}}$, uses a Uniform prior\n",
    "- `beta`, or $\\beta$, uses a Uniform prior\n",
    "\n",
    "An example priors file is below.\n",
    "\n",
    "```yaml\n",
    "---\n",
    "# NOTE that the tilde ~ below is a NULL; it should be used in the first\n",
    "#   position (where Python starts counting, at 0) when there is no PFT 0\n",
    "gl_sh:\n",
    "  mu: [~, -2.41, -4.25, -2.41, -4.25, -3.45, -3.91, -3.91, -3.45, -3.45, -3.22, ~, -3.45]\n",
    "  sigma: [~, 0.1, 0.1, 0.1, 0.1, 0.71, 0.1, 0.1, 0.71, 0.71, 0.1, ~, 0.71]\n",
    "gl_wv:\n",
    "  mu: [~, -2.41, -4.25, -2.41, -4.25, -3.45, -3.91, -3.91, -3.45, -3.45, -3.22, ~, -3.45]\n",
    "  sigma: [~, 0.1, 0.1, 0.1, 0.1, 0.71, 0.1, 0.1, 0.71, 0.71, 0.1, ~, 0.71]\n",
    "g_cuticular:\n",
    "  mu: [~, -10.2, -10.75, -10.12, -10.08, -10.38, -10.42, -10.42, -10.19, -10.19, -9.57, ~, -8.79]\n",
    "  sigma: [~, 1.02, 1.14, 0.89, 0.82, 1.05, 1.04, 1.04, 1.44, 1.44, 1.26, ~, 0.26]\n",
    "csl:\n",
    "  mu: [~, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.11, ~, -4.29]\n",
    "  sigma: [~, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.89, ~, 0.65]\n",
    "# These parameters have a Uniform prior, so we specify the lower and upper bounds\n",
    "rbl_min:\n",
    "  lower: [~, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, ~, 10]\n",
    "  upper: [~, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, ~, 99]\n",
    "rbl_max:\n",
    "  lower: [~, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, ~, 100]\n",
    "  upper: [~, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, ~, 1000]\n",
    "beta:\n",
    "  lower: [~, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~, 0]\n",
    "  upper: [~, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, ~, 1000]\n",
    "```\n",
    "\n",
    "**Each MOD16 parameter has one or more statistical parameters describing its prior distribution.** These statistical parameters are given in a list because there should be one value for each PFT. The tilde, `~`, character indicates no prior parameters are provided for that PFT, and are used to make sure that the numeric position of statistical parameter value in the list corresponds to the numeric PFT code, considering the way that Python counts. That's why every list begins with `~`: Python starts counting at zero (0) but there is no PFT coded 0.\n",
    "\n",
    "- **For LogNormal (or Normal) priors,** the `mu` and `sigma` keys indicate the mean and standard deviation of the prior, respectively.\n",
    "- **For Uniform priors,** the `lower` and `upper` keys indicate the minimum and maximum bounds on the Uniform distribution.\n",
    "\n",
    "**These prior distributions are defined in the `MOD16StochasticSampler.compile_et_model()` function in `calibration.py`.** For more information, consult [the PyMC documentation.](https://www.pymc.io/projects/docs/en/latest/api/distributions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196be32-3f60-4b3f-8142-b8ada743b9db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Running the Calibration\n",
    "\n",
    "When the files described above are in place, you're ready to calibrate MOD16! Below, we run the calibration for PFT 1. It's that simple! Here, we also add `--save-fig=True` so that we save a file version of the trace plot at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a4543-5592-4b4f-b005-704b19581d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py tune --pft=1 --save-fig=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30ba45-f30d-4eac-ab0b-7ad01a349ae3",
   "metadata": {},
   "source": [
    "If we wanted to provide a path to a specific configuration file (other than the default, `data/MOD16_calibration_config.yaml`), then we could do so with:\n",
    "\n",
    "```sh\n",
    "python ../mod16/calibration.py tune --pft=1 --config=path/to/my/configuration_file.yaml\n",
    "```\n",
    "\n",
    "You should see some output that looks like this:\n",
    "\n",
    "```\n",
    "Using configuration file: \"/usr/local/dev/MOD16/mod16/data/MOD16_calibration_config.yaml\"\n",
    "Masking out validation data...\n",
    "Loading driver datasets...\n",
    "Initializing sampler...\n",
    "-- RMSD at the initial point: 19.035\n",
    "Compiling model...\n",
    "Multiprocess sampling (3 chains in 3 jobs)\n",
    "DEMetropolisZ: [gl_sh, gl_wv, g_cuticular, csl, rbl_min, rbl_max, beta]\n",
    " |██-----------| 21.38% [1283/6000 00:18<01:07 Sampling 3 chains, 0 divergences]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b172141-d5e4-4a99-acc4-ffeaa66eab57",
   "metadata": {},
   "source": [
    "### Output Files\n",
    "\n",
    "There is usually a single output file associated with a successful run, a netCDF4 file (`*.nc4`) that is determined by the `backend_template` option of your configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a717d7-785e-47e9-bac0-090ddd110883",
   "metadata": {},
   "source": [
    "### Using k-folds Cross Validation\n",
    "\n",
    "If you have a small training dataset and want to use $k$-folds cross-validation, you can do so by adding a command-line argument:\n",
    "\n",
    "```sh\n",
    "# e.g., 3-fold cross-validation\n",
    "python ../mod16/calibration.py tune --pft=1 --k-folds=3\n",
    "```\n",
    "\n",
    "What's different when using $k$-folds?\n",
    "\n",
    "- The sampler will run $k$ times. No trace plot(s) will be shown.\n",
    "- There will be $k$ output netCDF4 (backend) files.\n",
    "- There will be an additional output HDF5 file. This file contains the numeric indices of the samples used; the indices correspond to the flattened (1D) array of tower observations *after NaNs have been removed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30ea6e-3ae1-41f2-ba4a-eac5860ffb3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Diagnostics\n",
    "\n",
    "Once you have an output netCDF4 backend associated with calibrating one of your PFTs, you're ready to inspect the trace to see that you have a good sample of the posterior.\n",
    "\n",
    "### Diagnosing Autocorrelation\n",
    "\n",
    "The first step should be to diagnose autocorrelation in the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec158c-5230-4355-8c46-ea62a0e427b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py plot-autocorr --pft=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1238a-adad-48ea-8b23-a77e6aa3a470",
   "metadata": {},
   "source": [
    "If there is significant autocorrelation (bars exceed the height of the gray shaded area), thinning the chain can remove it. You can also burn-in (remove the first $N$ samples), which probably won't help with autocorrelation but can help remove samples from the beginning of the chain, before the sampler settled.\n",
    "\n",
    "Below, we thin by 10 (take every 10th sample) and burn-in 100 samples (throw away the first 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3303a-b5d8-403c-ab5d-411589cee9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py plot-autocorr --pft=1 --burn=100 --thin=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4b8fa-63b7-488a-9057-80deb175283d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exporting the Posterior\n",
    "\n",
    "When you're satisfied there is no autocorrelation in the posterior, you can export it to an HDF5 file for later statistical summary.\n",
    "\n",
    "```sh\n",
    "python ../mod16/calibration.py export-posterior <model_name> <parameter_name> <output_path>\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `<model_name>` should always be `ET`, for now.\n",
    "- `<parameter_name>` is the name of the parameter for which you want to export the posterior.\n",
    "- `<output_path>` is the file path of an HDF5 file, to be created on your file system.\n",
    "\n",
    "See the example below.\n",
    "\n",
    "**This step should only be run (and will only work) once you have a sample for every PFT in the `valid_PFT` configuration option.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8842c8-bbce-4838-abcc-33b7facd9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../mod16/calibration.py export-posterior ET g_cuticular /home/arthur/MOD16_g_cuticular_sample.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
